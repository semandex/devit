{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T15:20:08.774879300Z",
     "start_time": "2023-11-10T15:20:08.753203200Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import os.path as osp\n",
    "import torchvision as tv\n",
    "from glob import glob\n",
    "from detectron2.data import transforms as T\n",
    "from torchvision.transforms import functional as tvF\n",
    "torch.set_grad_enabled(False)\n",
    "to_pil = tv.transforms.functional.to_pil_image\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import torchvision.ops as ops\n",
    "import torch.nn.functional as F\n",
    "RGB = tv.io.ImageReadMode.RGB\n",
    "\n",
    "pixel_mean = torch.Tensor([123.675, 116.280, 103.530]).view(3, 1, 1)\n",
    "pixel_std = torch.Tensor([58.395, 57.120, 57.375]).view(3, 1, 1)\n",
    "normalize_image = lambda x: (x - pixel_mean) / pixel_std\n",
    "\n",
    "def iround(x): return int(round(x))\n",
    "\n",
    "def resize_to_closest_14x(img):\n",
    "    h, w = img.shape[1:]\n",
    "    h, w = max(iround(h / 14), 1) * 14, max(iround(w / 14), 1) * 14\n",
    "    return tvF.resize(img, (h, w), interpolation=tvF.InterpolationMode.BICUBIC)\n",
    "\n",
    "root = osp.join(os.path.abspath(''), '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T15:20:15.083101700Z",
     "start_time": "2023-11-10T15:20:11.089817200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\IRandman/.cache\\torch\\hub\\facebookresearch_dinov2_main\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14')\n",
    "device = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T15:20:15.097862Z",
     "start_time": "2023-11-10T15:20:15.085097700Z"
    }
   },
   "outputs": [],
   "source": [
    "resize_op = T.ResizeShortestEdge(\n",
    "                short_edge_length=800,\n",
    "                max_size=1333,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T15:20:15.125478200Z",
     "start_time": "2023-11-10T15:20:15.103880700Z"
    }
   },
   "outputs": [],
   "source": [
    "# reading metas\n",
    "class2images = {}\n",
    "# for f in glob(osp.join(root, 'datasets/person/*')):\n",
    "for f in glob(osp.join(root, 'demo/data/images/rd-crcl/*.png')):\n",
    "    if osp.isfile(f) and 'mask' not in f:\n",
    "        image_file = f\n",
    "        class_name = osp.basename(osp.dirname(f))\n",
    "        mask_file = osp.splitext(f)[0] + '.mask.png'\n",
    "        if not os.path.exists(mask_file):\n",
    "            continue\n",
    "        if class_name not in class2images:\n",
    "            class2images[class_name] = []\n",
    "        class2images[class_name.strip().lower()].append((image_file, mask_file)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T15:20:16.010759500Z",
     "start_time": "2023-11-10T15:20:15.994714200Z"
    }
   },
   "outputs": [],
   "source": [
    "classes = sorted(class2images.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "['rd-crcl']"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T15:20:17.430920600Z",
     "start_time": "2023-11-10T15:20:17.386317300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T15:20:18.685283200Z",
     "start_time": "2023-11-10T15:20:18.677240700Z"
    }
   },
   "outputs": [],
   "source": [
    "# to_pil(tv.io.read_image(image_file, RGB) * (tv.io.read_image(mask_file) != 0).to(torch.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T15:20:29.463688800Z",
     "start_time": "2023-11-10T15:20:19.730035700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.13s/it]\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "class2tokens = {}\n",
    "for cls, images in tqdm(class2images.items()):\n",
    "    class2tokens[cls] = []\n",
    "    for image_file, mask_file in images:\n",
    "        image = tv.io.read_image(image_file, RGB).permute(1, 2, 0)\n",
    "        resize = resize_op.get_transform(image)\n",
    "        mask = tv.io.read_image(mask_file).permute(1, 2, 0)\n",
    "\n",
    "        mask = torch.as_tensor(resize.apply_segmentation(mask.numpy())).permute(2, 0, 1) != 0\n",
    "        image = torch.as_tensor(resize.apply_image(image.numpy())).permute(2, 0, 1)\n",
    "\n",
    "        image14 = resize_to_closest_14x(image)\n",
    "        mask_h, mask_w = image14.shape[1] // 14, image14.shape[2] // 14\n",
    "        nimage14 = normalize_image(image14)[None, ...]\n",
    "        r = model.get_intermediate_layers(nimage14.to(device), \n",
    "                                return_class_token=True, reshape=True)    \n",
    "        patch_tokens = r[0][0][0].cpu()\n",
    "        mask14 = tvF.resize(mask, (mask_h, mask_w))\n",
    "        if mask14.sum() <= 0.5:\n",
    "            continue\n",
    "        avg_patch_token = (mask14 * patch_tokens).flatten(1).sum(1) / mask14.sum()\n",
    "        class2tokens[cls].append(avg_patch_token) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T15:20:35.183447600Z",
     "start_time": "2023-11-10T15:20:35.174372Z"
    }
   },
   "outputs": [],
   "source": [
    "for cls in class2tokens:\n",
    "    class2tokens[cls] = torch.stack(class2tokens[cls]).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T15:20:35.963002Z",
     "start_time": "2023-11-10T15:20:35.947492600Z"
    }
   },
   "outputs": [],
   "source": [
    "prototypes = F.normalize(torch.stack([class2tokens[c] for c in classes]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T15:20:36.443375200Z",
     "start_time": "2023-11-10T15:20:36.435121500Z"
    }
   },
   "outputs": [],
   "source": [
    "category_dict = {\n",
    "    'prototypes': prototypes,\n",
    "    'label_names': classes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T15:20:37.052455Z",
     "start_time": "2023-11-10T15:20:37.037828400Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(category_dict, 'rd-crcl_prototypes.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('detrex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29d762b5af5aadcdfbfc52cb464c47d95fae315fd3aca7ff346c6b95b4d3f3d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
